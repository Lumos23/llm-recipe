batch_size_training: '16'
checkpoint_type: StateDictType.SHARDED_STATE_DICT
dataset: harmfulness_eval_dataset
dist_checkpoint_folder: ft-llama-2-13b-chat-sorry-bench-bs=16-lr=1e-5
dist_checkpoint_root_folder: finetuned_models/
enable_fsdp: 'True'
freeze_layers: 'False'
fsdp_activation_checkpointing: 'True'
gamma: '0.85'
gradient_accumulation_steps: '1'
low_cpu_fsdp: 'False'
lr: 1e-05
mixed_precision: 'True'
model_name: meta-llama/Meta-Llama-3-8B-Instruct
num_epochs: '3'
num_freeze_layers: '1'
num_workers_dataloader: '1'
one_gpu: 'False'
optimizer: AdamW
output_dir: finetuned_models
peft_method: lora
pure_bf16: 'True'
quantization: 'False'
run_validation: 'False'
save_every_epoch: 'False'
save_model: 'True'
save_optimizer: 'False'
seed: '4943'
sharding_strategy: ShardingStrategy.FULL_SHARD
use_fast_kernels: 'False'
use_fp16: 'False'
use_peft: 'False'
val_batch_size: '1'
weight_decay: '0'
